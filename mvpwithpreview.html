<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Contextual Transcription Companion</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            max-width: 800px;
            margin: 0 auto;
            background-color: #f0f4f8;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: white;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.1);
            padding: 20px;
            width: 100%;
        }
        .media-container {
            display: flex;
            justify-content: space-between;
            width: 100%;
            gap: 20px;
        }
        #videoPreview, #capturedImage {
            width: 48%;
            max-width: 640px;
            height: 480px;
            background-color: #000;
            border-radius: 10px;
            object-fit: cover;
        }
        #recordButton {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            font-size: 16px;
            margin: 20px 0;
            cursor: pointer;
            border-radius: 8px;
            transition: all 0.3s ease;
        }
        #recordButton.recording {
            background-color: #f44336;
            animation: pulse 1s infinite;
        }
        #transcription {
            width: 100%;
            max-width: 640px;
            background-color: #e9ecef;
            border: 2px dashed #3498db;
            padding: 20px;
            margin-top: 20px;
            border-radius: 8px;
            min-height: 100px;
            text-align: center;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="media-container">
            <video id="videoPreview" autoplay playsinline></video>
            <canvas id="capturedImage" style="display:none;"></canvas>
        </div>
        <button id="recordButton">Start Recording</button>
        <div id="transcription">
            Transcription will appear here...
        </div>
    </div>

    <script>
        class ContextualTranscription {
            constructor() {
                this.videoPreview = document.getElementById('videoPreview');
                this.capturedImage = document.getElementById('capturedImage');
                this.recordButton = document.getElementById('recordButton');
                this.transcriptionDiv = document.getElementById('transcription');
                
                // Speech Recognition Setup
                this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                
                // Stream and capture variables
                this.mediaStream = null;
                
                // Initialize components
                this.setupCameraPreview();
                this.setupSpeechRecognition();
            }

            async setupCameraPreview() {
                try {
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({
                        video: { 
                            width: { ideal: 640 },
                            height: { ideal: 480 }
                        },
                        audio: false
                    });
                    this.videoPreview.srcObject = this.mediaStream;
                } catch (error) {
                    this.handleError(`Camera Error: ${error.message}`);
                }
            }

            setupSpeechRecognition() {
                this.recognition.continuous = false;
                this.recognition.interimResults = false;
                this.recognition.lang = 'en-US';

                this.recognition.onstart = () => {
                    this.recordButton.textContent = 'Recording...';
                    this.recordButton.classList.add('recording');
                };

                this.recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    this.transcriptionDiv.textContent = transcript;
                    this.transcriptionDiv.style.color = '#2c3e50';
                    
                    // Capture image after successful transcription
                    this.captureImage();
                };

                this.recognition.onerror = (event) => {
                    this.handleError(`Error: ${event.error}`);
                };

                this.recognition.onend = () => {
                    this.resetButton();
                };

                this.recordButton.onclick = () => this.toggleRecording();
            }

            captureImage() {
                try {
                    // Create canvas context
                    const ctx = this.capturedImage.getContext('2d');
                    
                    // Match canvas to video dimensions
                    this.capturedImage.width = this.videoPreview.videoWidth;
                    this.capturedImage.height = this.videoPreview.videoHeight;
                    
                    // Draw current video frame
                    ctx.drawImage(this.videoPreview, 0, 0, 
                        this.capturedImage.width, 
                        this.capturedImage.height
                    );
                    
                    // Make canvas visible
                    this.capturedImage.style.display = 'block';
                } catch (error) {
                    this.handleError(`Image Capture Error: ${error.message}`);
                }
            }

            toggleRecording() {
                try {
                    if (this.recognition.listening) {
                        this.recognition.stop();
                    } else {
                        this.recognition.start();
                    }
                } catch (error) {
                    this.handleError('Speech recognition not supported');
                }
            }

            handleError(message) {
                this.transcriptionDiv.textContent = message;
                this.transcriptionDiv.style.color = '#e74c3c';
                this.resetButton();
            }

            resetButton() {
                this.recordButton.textContent = 'Start Recording';
                this.recordButton.classList.remove('recording');
                this.recognition.listening = false;
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', () => {
            if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
                alert('Your browser does not support speech recognition. Try Chrome or Edge.');
                return;
            }
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('Your browser does not support camera access.');
                return;
            }
            new ContextualTranscription();
        });
    </script>
</body>
</html>